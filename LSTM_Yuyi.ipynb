{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mm7N-1hvfvql"
      },
      "outputs": [],
      "source": [
        "!pip install git+https://github.com/macrosynergy/macrosynergy@develop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TVbZZirmy_x3"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import os\n",
        "\n",
        "\n",
        "import macrosynergy.management as msm\n",
        "import macrosynergy.panel as msp\n",
        "import macrosynergy.signal as mss\n",
        "import macrosynergy.pnl as msn\n",
        "\n",
        "\n",
        "import os\n",
        "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
        "    for filename in filenames:\n",
        "        print(os.path.join(dirname, filename))\n",
        "\n",
        "import warnings\n",
        "\n",
        "warnings.simplefilter(\"ignore\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YrHmUht0zExb"
      },
      "outputs": [],
      "source": [
        "# Cross-sections of interest\n",
        "\n",
        "cids_dm = [\"AUD\", \"CAD\", \"CHF\", \"EUR\", \"GBP\", \"JPY\", \"NOK\", \"NZD\", \"SEK\", \"USD\"]\n",
        "cids_em = [\n",
        "    \"CLP\",\n",
        "    \"COP\",\n",
        "    \"CZK\",\n",
        "    \"HUF\",\n",
        "    \"IDR\",\n",
        "    \"ILS\",\n",
        "    \"INR\",\n",
        "    \"KRW\",\n",
        "    \"MXN\",\n",
        "    \"PLN\",\n",
        "    \"THB\",\n",
        "    \"TRY\",\n",
        "    \"TWD\",\n",
        "    \"ZAR\",\n",
        "]\n",
        "cids = cids_dm + cids_em\n",
        "cids_du = cids_dm + cids_em\n",
        "cids_dux = list(set(cids_du) - set([\"IDR\", \"NZD\"]))\n",
        "cids_xg2 = list(set(cids_dux) - set([\"EUR\", \"USD\"]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3iJb6HnDzJnb"
      },
      "outputs": [],
      "source": [
        "# Quantamental categories of interest\n",
        "\n",
        "ecos = [\n",
        "    \"CPIC_SA_P1M1ML12\",\n",
        "    \"CPIC_SJA_P3M3ML3AR\",\n",
        "    \"CPIC_SJA_P6M6ML6AR\",\n",
        "    \"CPIH_SA_P1M1ML12\",\n",
        "    \"CPIH_SJA_P3M3ML3AR\",\n",
        "    \"CPIH_SJA_P6M6ML6AR\",\n",
        "    \"INFTEFF_NSA\",\n",
        "    \"INTRGDP_NSA_P1M1ML12_3MMA\",\n",
        "    \"INTRGDPv5Y_NSA_P1M1ML12_3MMA\",\n",
        "    \"PCREDITGDP_SJA_D1M1ML12\",\n",
        "    \"PCREDITBN_SJA_P1M1ML12\",\n",
        "    \"RGDP_SA_P1Q1QL4_20QMA\",\n",
        "    \"RYLDIRS02Y_NSA\",\n",
        "    \"RYLDIRS05Y_NSA\",\n",
        "]\n",
        "mkts = [\n",
        "    \"DU02YXR_NSA\",\n",
        "    \"DU05YXR_NSA\",\n",
        "    \"DU02YXR_VT10\",\n",
        "    \"DU05YXR_VT10\",\n",
        "    \"EQXR_NSA\",\n",
        "    \"EQXR_VT10\",\n",
        "    \"FXXR_NSA\",\n",
        "    \"FXXR_VT10\",\n",
        "    \"FXCRR_NSA\",\n",
        "    \"FXTARGETED_NSA\",\n",
        "    \"FXUNTRADABLE_NSA\",\n",
        "]\n",
        "\n",
        "xcats = ecos + mkts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "uoCMHiC_zP_7"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>cid</th>\n",
              "      <th>xcat</th>\n",
              "      <th>real_date</th>\n",
              "      <th>value</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>3350268</th>\n",
              "      <td>ZAR</td>\n",
              "      <td>RGDP_SA_P1Q1QL4_20QMA</td>\n",
              "      <td>2023-08-31</td>\n",
              "      <td>0.534737</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3350269</th>\n",
              "      <td>ZAR</td>\n",
              "      <td>RYLDIRS02Y_NSA</td>\n",
              "      <td>2023-08-31</td>\n",
              "      <td>3.230619</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3350270</th>\n",
              "      <td>ZAR</td>\n",
              "      <td>RYLDIRS05Y_NSA</td>\n",
              "      <td>2023-08-31</td>\n",
              "      <td>3.543863</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         cid                   xcat  real_date     value\n",
              "3350268  ZAR  RGDP_SA_P1Q1QL4_20QMA 2023-08-31  0.534737\n",
              "3350269  ZAR         RYLDIRS02Y_NSA 2023-08-31  3.230619\n",
              "3350270  ZAR         RYLDIRS05Y_NSA 2023-08-31  3.543863"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Index: 3350271 entries, 0 to 3350270\n",
            "Data columns (total 4 columns):\n",
            " #   Column     Dtype         \n",
            "---  ------     -----         \n",
            " 0   cid        object        \n",
            " 1   xcat       object        \n",
            " 2   real_date  datetime64[ns]\n",
            " 3   value      float64       \n",
            "dtypes: datetime64[ns](1), float64(1), object(2)\n",
            "memory usage: 127.8+ MB\n"
          ]
        }
      ],
      "source": [
        "# load the dataset:\n",
        "\n",
        "df = pd.read_csv('JPMaQS_Quantamental_Indicators.csv', index_col=0, parse_dates=['real_date'])\n",
        "\n",
        "scols = [\"cid\", \"xcat\", \"real_date\", \"value\"]  # required columns\n",
        "df = df[scols].copy()\n",
        "display (df.tail(3))\n",
        "df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "uOueTUCM0rOj"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array(['CPIC_SA_P1M1ML12', 'CPIC_SJA_P3M3ML3AR', 'CPIC_SJA_P6M6ML6AR',\n",
              "       'CPIH_SA_P1M1ML12', 'CPIH_SJA_P3M3ML3AR', 'CPIH_SJA_P6M6ML6AR',\n",
              "       'FXTARGETED_NSA', 'FXUNTRADABLE_NSA', 'FXXR_NSA', 'FXXR_VT10',\n",
              "       'INFTEFF_NSA', 'INTRGDP_NSA_P1M1ML12_3MMA',\n",
              "       'INTRGDPv5Y_NSA_P1M1ML12_3MMA', 'PCREDITBN_SJA_P1M1ML12',\n",
              "       'PCREDITGDP_SJA_D1M1ML12', 'RGDP_SA_P1Q1QL4_20QMA',\n",
              "       'RYLDIRS02Y_NSA', 'RYLDIRS05Y_NSA', 'DU02YXR_NSA', 'DU02YXR_VT10',\n",
              "       'DU05YXR_NSA', 'DU05YXR_VT10', 'EQXR_NSA', 'EQXR_VT10',\n",
              "       'FXCRR_NSA'], dtype=object)"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "array(['AUD', 'CAD', 'CHF', 'CLP', 'COP', 'CZK', 'EUR', 'GBP', 'HUF',\n",
              "       'IDR', 'ILS', 'INR', 'JPY', 'KRW', 'MXN', 'NOK', 'NZD', 'PLN',\n",
              "       'SEK', 'THB', 'TRY', 'TWD', 'USD', 'ZAR'], dtype=object)"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "display(df['xcat'].unique())\n",
        "display(df['cid'].unique())\n",
        "df['ticker'] = df['cid'] + \"_\" + df[\"xcat\"]\n",
        "df.set_index('real_date', inplace=True)\n",
        "df.sort_index(inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {},
      "outputs": [],
      "source": [
        "# LSTM particular implementations\n",
        "\n",
        "from sklearn.model_selection import TimeSeriesSplit\n",
        "from keras import Sequential\n",
        "from keras.layers import LSTM\n",
        "from keras.layers import Dense\n",
        "from keras_tuner import RandomSearch\n",
        "from keras.metrics import mean_squared_error\n",
        "\n",
        "# only consider the USD dollars for now\n",
        "# only did USD for now, can be extended to other currencies\n",
        "df_USD = df[df[\"cid\"] == 'USD'] \n",
        "\n",
        "# make the xcat features into columns\n",
        "df_USD = df_USD.pivot_table(index='real_date', columns='xcat', values='value', aggfunc='first')\n",
        "\n",
        "df_USD = df_USD.reset_index()\n",
        "\n",
        "# deals with missing data\n",
        "df_USD = df_USD.dropna()\n",
        "\n",
        "# split into training and test data\n",
        "tss = TimeSeriesSplit(n_splits = 4)\n",
        "\n",
        "for train_index, test_index in tss.split(df_USD):\n",
        "    pass\n",
        "\n",
        "train_set = df_USD.iloc[train_index]\n",
        "test_set = df_USD.iloc[test_index]\n",
        "\n",
        "tss = TimeSeriesSplit(n_splits = 3)\n",
        "\n",
        "for train_index, test_index in tss.split(train_set):\n",
        "    pass\n",
        "\n",
        "development_set = train_set.iloc[train_index]\n",
        "val_set = df_USD.iloc[test_index]\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {},
      "outputs": [],
      "source": [
        "dev_y = np.array(development_set['DU05YXR_VT10'])\n",
        "dev_y = dev_y.reshape(dev_y.shape[0],1)\n",
        "\n",
        "dev_X = np.array(development_set.drop(columns=['DU05YXR_VT10', 'real_date']))\n",
        "dev_X = dev_X.reshape(dev_X.shape[0],dev_X.shape[1],1)\n",
        "\n",
        "test_y = np.array(test_set['DU05YXR_VT10'])\n",
        "test_y = test_y.reshape(test_y.shape[0],1)\n",
        "\n",
        "test_X = np.array(test_set.drop(columns=['DU05YXR_VT10','real_date']))\n",
        "test_X = test_X.reshape(test_X.shape[0],test_X.shape[1],1)\n",
        "\n",
        "val_y = np.array(val_set['DU05YXR_VT10'])\n",
        "val_y = val_y.reshape(val_set.shape[0],1)\n",
        "\n",
        "val_X = np.array(val_set.drop(columns=['DU05YXR_VT10','real_date']))\n",
        "val_X = val_X.reshape(val_X.shape[0],val_X.shape[1],1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Hyperparameter training part\n",
        "\n",
        "def build_model(hp):\n",
        "  model = Sequential()\n",
        "\n",
        "  model = Sequential()\n",
        "\n",
        "  model.add(LSTM(hp.Choice('units', [64, 128, 256]), activation='relu', input_shape=(dev_X.shape[1], 1), return_sequences=True))\n",
        "  model.add(LSTM(hp.Choice('units', [8, 16, 32]), activation='relu', return_sequences=False))\n",
        "  model.add(Dense(1))\n",
        "  model.compile(hp.Choice('optimizer', [\"adam\", \"RMSProp\", \"SGD\"]),loss='mse', metrics=[mean_squared_error])\n",
        "  return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {},
      "outputs": [],
      "source": [
        "tuner = RandomSearch(\n",
        "    build_model,\n",
        "    objective='val_loss',\n",
        "    max_trials=5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Trial 5 Complete [00h 00m 10s]\n",
            "val_loss: 0.4786025881767273\n",
            "\n",
            "Best val_loss So Far: 0.08929534256458282\n",
            "Total elapsed time: 00h 02m 47s\n"
          ]
        }
      ],
      "source": [
        "tuner.search(dev_X, dev_y, epochs=10, validation_data=(val_X, val_y))\n",
        "best_model = tuner.get_best_models()[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "116/116 [==============================] - 2s 8ms/step - loss: 0.0912 - mean_squared_error: 0.0912 - val_loss: 0.1098 - val_mean_squared_error: 0.1098\n",
            "Epoch 2/10\n",
            "116/116 [==============================] - 1s 9ms/step - loss: 0.0787 - mean_squared_error: 0.0787 - val_loss: 0.0997 - val_mean_squared_error: 0.0997\n",
            "Epoch 3/10\n",
            "116/116 [==============================] - 1s 8ms/step - loss: 0.0800 - mean_squared_error: 0.0800 - val_loss: 0.0793 - val_mean_squared_error: 0.0793\n",
            "Epoch 4/10\n",
            "116/116 [==============================] - 1s 8ms/step - loss: 0.0749 - mean_squared_error: 0.0749 - val_loss: 0.0744 - val_mean_squared_error: 0.0744\n",
            "Epoch 5/10\n",
            "116/116 [==============================] - 1s 8ms/step - loss: 0.0677 - mean_squared_error: 0.0677 - val_loss: 0.0862 - val_mean_squared_error: 0.0862\n",
            "Epoch 6/10\n",
            "116/116 [==============================] - 1s 8ms/step - loss: 0.0704 - mean_squared_error: 0.0704 - val_loss: 0.0828 - val_mean_squared_error: 0.0828\n",
            "Epoch 7/10\n",
            "116/116 [==============================] - 1s 8ms/step - loss: 0.0635 - mean_squared_error: 0.0635 - val_loss: 0.1008 - val_mean_squared_error: 0.1008\n",
            "Epoch 8/10\n",
            "116/116 [==============================] - 1s 8ms/step - loss: 0.0748 - mean_squared_error: 0.0748 - val_loss: 0.1096 - val_mean_squared_error: 0.1096\n",
            "Epoch 9/10\n",
            "116/116 [==============================] - 1s 8ms/step - loss: 0.0646 - mean_squared_error: 0.0646 - val_loss: 0.0687 - val_mean_squared_error: 0.0687\n",
            "Epoch 10/10\n",
            "116/116 [==============================] - 1s 8ms/step - loss: 0.0587 - mean_squared_error: 0.0587 - val_loss: 0.0822 - val_mean_squared_error: 0.0822\n",
            "39/39 [==============================] - 0s 2ms/step - loss: 0.1418 - mean_squared_error: 0.1418\n",
            "Mean Squared Loss is: 0.14177067577838898\n"
          ]
        }
      ],
      "source": [
        "# Retrain on the optimal hyperparameter and evaluate on the test set\n",
        "\n",
        "history = best_model.fit(dev_X, dev_y, epochs=10, validation_data=(val_X, val_y))\n",
        "records = best_model.evaluate(test_X, test_y)\n",
        "\n",
        "print(\"Mean Squared Loss is: \" + str(records[1]))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
